{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "ROOT_PATH = \"C:\\\\Users\\\\micha\\\\Downloads\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_of_genes = 500\n",
    "num_of_samples = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTEX-1117F-0226-SM-5GZZ7\n"
     ]
    }
   ],
   "source": [
    "#order of samples in this file defines sample id\n",
    "sample_columns = os.path.join(ROOT_PATH, \"Sample_Columns.txt\")\n",
    "sample_file = open(sample_columns,'r')\n",
    "sample_names = []\n",
    "for line in sample_file:\n",
    "    parts = line.split('\\t')\n",
    "    for part in parts:\n",
    "        sample_name = part.rstrip()\n",
    "        sample_names.append(sample_name)\n",
    "#sample_names = sample_file.read().split()\n",
    "#remove Name and Description entries\n",
    "del(sample_names[0])\n",
    "del(sample_names[0])\n",
    "print(sample_names[0])\n",
    "sample_to_id = {}\n",
    "sample_id = 1\n",
    "for name in sample_names:\n",
    "    #name = name.rstrip()\n",
    "    sample_to_id[name] = sample_id\n",
    "    #print(name + \" \" + str(sample_id))\n",
    "    sample_id = sample_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#do not need this section of code for current version\n",
    "gene_column = os.path.join(ROOT_PATH, \"Gene_Column.txt\")\n",
    "gene_file = open(gene_column,'r')\n",
    "gene_names = []\n",
    "gene_counter = 1\n",
    "for line in gene_file:\n",
    "    if (gene_counter < 51):\n",
    "        gene_names.append(line.rstrip())\n",
    "        #gene_names.append(str(gene_counter))\n",
    "        gene_counter = gene_counter + 1\n",
    "gene_names.append(\"Tissue_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_to_tissue = {}\n",
    "tissue_to_id = {}\n",
    "tissues = []\n",
    "sample_tissue_path = os.path.join(ROOT_PATH, \"Sample_to_Tissue.txt\")\n",
    "sample_tissue_file = open(sample_tissue_path,'r')\n",
    "tissue_id = 1\n",
    "for line in sample_tissue_file:\n",
    "    parts = line.split('\\t')\n",
    "    sample_name = parts[0].rstrip()\n",
    "    if (sample_name in sample_to_id.keys()):\n",
    "        sample_id = sample_to_id[sample_name]\n",
    "        tissue = parts[1].rstrip()\n",
    "        tissue = tissue.replace(',', ' ')\n",
    "\n",
    "        #tissues.append(tissue)\n",
    "        if (tissue not in tissue_to_id.keys()):\n",
    "            tissue_to_id[tissue] = tissue_id\n",
    "            tissues.append(tissue)\n",
    "            tissue_id = tissue_id + 1\n",
    "        sample_to_tissue[sample_id] = tissue_to_id[tissue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the header in the training and test files needs to be a comma-separated\n",
    "#list of number of entries, number of features, followed by list of all possible classes/categories \n",
    "header_string = str(num_of_samples) + \",\" + str(num_of_genes) +\",\" + \",\".join(tissues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "num_of_classes = len(tissues)\n",
    "print(str(num_of_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpm_data = os.path.join(ROOT_PATH, \"GTEx_Analysis_2016-01-15_v7_RNASeQCv1.1.8_gene_tpm.gct\")\n",
    "#use first 50 genes\n",
    "reader = pd.read_table(tpm_data, sep = \"\\t\",skiprows = [0,1], nrows=num_of_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING = \"training7.csv\"\n",
    "TEST = \"test7.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(TRAINING, \"w\")\n",
    "f.write(header_string + \"\\n\")\n",
    "i = 2\n",
    "sample_id = 1\n",
    "#use first 500 samples\n",
    "while i < 2 + num_of_samples:\n",
    "    list = []\n",
    "    tissue_id = sample_to_tissue[sample_id] \n",
    "    #each column contains expression values for each gene in a sample\n",
    "    for index, column in reader.iterrows() :\n",
    "        list.append(str(round(column[i],0)))\n",
    "    #print(len(list))\n",
    "    #append tissue_id to end of line\n",
    "    list.append(str(tissue_id))\n",
    "    line = \",\".join(list) + \"\\n\"\n",
    "    f.write(line)\n",
    "    sample_id =  sample_id + 2\n",
    "    i = i + 2\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_test = open(TEST, \"w\")\n",
    "f_test.write(header_string + \"\\n\")\n",
    "\n",
    "i = 3\n",
    "sample_id = 2\n",
    "while i < 2 + num_of_samples:\n",
    "    list = []\n",
    "    tissue_id = sample_to_tissue[sample_id] \n",
    "    #each column contains expression values for each gene in a sample\n",
    "    for index, column in reader.iterrows() :\n",
    "        list.append(str(round(column[i],0)))\n",
    "    #print(len(list))\n",
    "    #append tissue_id to end of line\n",
    "    list.append(str(tissue_id))\n",
    "    line = \",\".join(list) + \"\\n\"\n",
    "    f_test.write(line)\n",
    "    sample_id = sample_id + 2\n",
    "    i = i + 2\n",
    "f_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load datasets.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=TRAINING,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=TEST,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[num_of_genes])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\micha\\AppData\\Local\\Temp\\tmpfuvu65rb\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\micha\\\\AppData\\\\Local\\\\Temp\\\\tmpfuvu65rb', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                          hidden_units=[10, 20, 10],\n",
    "                                          n_classes=54,\n",
    "                                          model_dir=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": np.array(training_set.data)},\n",
    "      y=np.array(training_set.target),\n",
    "      num_epochs=None,\n",
    "      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\micha\\AppData\\Local\\Temp\\tmpfuvu65rb\\model.ckpt.\n",
      "INFO:tensorflow:loss = 10185.3, step = 1\n",
      "INFO:tensorflow:global_step/sec: 492.253\n",
      "INFO:tensorflow:loss = 149.688, step = 101 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.255\n",
      "INFO:tensorflow:loss = 87.5721, step = 201 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.094\n",
      "INFO:tensorflow:loss = 154.117, step = 301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.276\n",
      "INFO:tensorflow:loss = 54.6652, step = 401 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.257\n",
      "INFO:tensorflow:loss = 113.056, step = 501 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.253\n",
      "INFO:tensorflow:loss = 77.9297, step = 601 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.279\n",
      "INFO:tensorflow:loss = 62.7609, step = 701 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.253\n",
      "INFO:tensorflow:loss = 112.234, step = 801 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.258\n",
      "INFO:tensorflow:loss = 50.4016, step = 901 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.255\n",
      "INFO:tensorflow:loss = 114.424, step = 1001 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.255\n",
      "INFO:tensorflow:loss = 67.5196, step = 1101 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.256\n",
      "INFO:tensorflow:loss = 67.483, step = 1201 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.255\n",
      "INFO:tensorflow:loss = 95.3047, step = 1301 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.277\n",
      "INFO:tensorflow:loss = 24.7696, step = 1401 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.621\n",
      "INFO:tensorflow:loss = 110.666, step = 1501 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.309\n",
      "INFO:tensorflow:loss = 41.6237, step = 1601 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.224\n",
      "INFO:tensorflow:loss = 38.9174, step = 1701 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.121\n",
      "INFO:tensorflow:loss = 102.128, step = 1801 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.256\n",
      "INFO:tensorflow:loss = 42.7817, step = 1901 (0.203 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\micha\\AppData\\Local\\Temp\\tmpfuvu65rb\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 71.467.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x16157468ef0>"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model.\n",
    "classifier.train(input_fn=train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": np.array(test_set.data)},\n",
    "      y=np.array(test_set.target),\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-10-22-20:21:10\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\micha\\AppData\\Local\\Temp\\tmpfuvu65rb\\model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-22-20:21:10\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.8415, average_loss = 0.524371, global_step = 2000, loss = 65.5463\n",
      "\n",
      "Test Accuracy: 0.841500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classify one new tissue sample.\n",
    "\n",
    "new_samples = np.array(\n",
    "#test example with 100 genes - need to update if number of included genes change\n",
    "    [[0.0,7.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5.0,322.0,30.0,9.0,7.0,2306.0,9.0,0.0,0.0,0.0,3.0,0.0,0.0,0.0,0.0,2.0,1.0,1.0,0.0,0.0,1.0,6.0,8.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,62.0,12.0,1.0,0.0,8.0,46.0,0.0,0.0,82.0,18.0,0.0,0.0,0.0,7.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,2.0,235.0,16.0,1.0,0.0,24.0,3.0,2.0,29.0,9.0,61.0,28.0,17.0,0.0,62.0]], dtype=np.float32)\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": new_samples},\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "\n",
    "predictions = classifier.predict(input_fn=predict_input_fn)\n",
    "#dir(predictions)\n",
    "d = next(predictions)\n",
    "print(type(d))\n",
    "print(d.keys())\n",
    "probs= d['probabilities']\n",
    "max_p_index = np.argmax(probs)\n",
    "print(max_p_index)\n",
    "print(tissues[max_p_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
