{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ROOT_PATH = \"C:\\\\Users\\\\micha\\\\Downloads\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_of_genes = 500\n",
    "num_of_samples = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#order of samples in this file defines sample id\n",
    "sample_columns = os.path.join(ROOT_PATH, \"Sample_Columns.txt\")\n",
    "sample_file = open(sample_columns,'r')\n",
    "sample_names = []\n",
    "for line in sample_file:\n",
    "    parts = line.split('\\t')\n",
    "    for part in parts:\n",
    "        sample_name = part.rstrip()\n",
    "        sample_names.append(sample_name)\n",
    "\n",
    "#remove Name and Description entries from sample_names\n",
    "del(sample_names[0])\n",
    "del(sample_names[0])\n",
    "\n",
    "#keep track of sample ids in dictionary for later reference\n",
    "sample_to_id = {}\n",
    "#local sample ids are sequential starting with 1\n",
    "sample_id = 1\n",
    "for name in sample_names:\n",
    "    sample_to_id[name] = sample_id\n",
    "    sample_id = sample_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#connect sample id to tissue id\n",
    "sample_to_tissue = {}\n",
    "tissue_to_id = {}\n",
    "tissues = []\n",
    "sample_tissue_path = os.path.join(ROOT_PATH, \"Sample_to_Tissue.txt\")\n",
    "sample_tissue_file = open(sample_tissue_path,'r')\n",
    "tissue_id = 1\n",
    "for line in sample_tissue_file:\n",
    "    parts = line.split('\\t')\n",
    "    sample_name = parts[0].rstrip()\n",
    "    if (sample_name in sample_to_id.keys()):\n",
    "        sample_id = sample_to_id[sample_name]\n",
    "        tissue = parts[1].rstrip()\n",
    "        tissue = tissue.replace(',', ' ')\n",
    "        #tissue ids are based on order discovered in Sample_to_Tissue.txt \n",
    "        if (tissue not in tissue_to_id.keys()):\n",
    "            tissue_to_id[tissue] = tissue_id\n",
    "            tissues.append(tissue)\n",
    "            tissue_id = tissue_id + 1\n",
    "        sample_to_tissue[sample_id] = tissue_to_id[tissue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the main data file, approximately 56K transcripts and 15K genes\n",
    "tpm_data = os.path.join(ROOT_PATH, \"GTEx_Analysis_2016-01-15_v7_RNASeQCv1.1.8_gene_tpm.gct\")\n",
    "#tpm data starts in 3rd row, 3 column \n",
    "reader = pd.read_table(tpm_data, sep = \"\\t\",skiprows = [0,1], nrows=num_of_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tpm values start in 3rd column of reader for sample 1, so index (i) begins at 2\n",
    "#training data set consist of samples with odd-numbered sample ids\n",
    "i = 2\n",
    "sample_id = 1\n",
    "train_target_list = []\n",
    "#train_data is ndarray for tpm arrays for all samples \n",
    "train_data = np.empty([0,num_of_genes])\n",
    "#data_for_one_sample is ndarray placeholder\n",
    "data_for_one_sample = np.array(0)\n",
    "while i < 2 + num_of_samples:\n",
    "    #train_data_list holds tpm values for one sample in temp list\n",
    "    train_data_list = []\n",
    "    tissue_id = sample_to_tissue[sample_id] \n",
    "    #each column contains expression values for each gene in the reader for a sample\n",
    "    for index, column in reader.iterrows() :\n",
    "        train_data_list.append(round(column[i],0))\n",
    "    data_for_one_sample = np.array(train_data_list)\n",
    "    train_target_list.append(tissue_id)\n",
    "    sample_id =  sample_id + 2\n",
    "    i = i + 2\n",
    "    train_data = np.vstack((train_data, data_for_one_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_targets = np.array(train_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test data set consist of samples with even-numbered ids starting with sample id = 2\n",
    "i = 3\n",
    "sample_id = 2\n",
    "test_target_list = []\n",
    "test_data = np.empty([0,num_of_genes])\n",
    "data_for_one_sample = np.array(0)\n",
    "while i < 2 + num_of_samples:\n",
    "    test_data_list = []\n",
    "    tissue_id = sample_to_tissue[sample_id] \n",
    "    #each column contains expression values for each gene in a sample\n",
    "    for index, column in reader.iterrows() :\n",
    "        test_data_list.append(round(column[i],0))\n",
    "    data_for_one_sample = np.array(test_data_list)\n",
    "    test_target_list.append(tissue_id)\n",
    "    sample_id =  sample_id + 2\n",
    "    i = i + 2\n",
    "    test_data = np.vstack((test_data, data_for_one_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#put targets/classes (tissue ids) into ndarray\n",
    "test_targets = np.array(test_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = gnb.fit(train_data,train_targets).predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total of 1000 points : 118\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total of %d points : %d\" %(test_data.shape[0],(test_targets != y_pred).sum()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need to get distribution of tissue types in train and test data sets\n",
    "#need to get distribution of tissue types for mislabeled points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
